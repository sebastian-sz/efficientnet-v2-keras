{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "efficientnet-v2-original-outputs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UgGs16yIEVI",
        "outputId": "9089656d-7b7e-4ba7-bd6c-5265d5784f75"
      },
      "source": [
        "# Clone repo and install dependencies\n",
        "\n",
        "!git clone https://github.com/google/automl.git\n",
        "!pip install tensorflow_addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'automl'...\n",
            "remote: Enumerating objects: 3996, done.\u001b[K\n",
            "remote: Counting objects: 100% (383/383), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 3996 (delta 226), reused 297 (delta 184), pack-reused 3613\u001b[K\n",
            "Receiving objects: 100% (3996/3996), 25.16 MiB | 19.46 MiB/s, done.\n",
            "Resolving deltas: 100% (2978/2978), done.\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OmvuKTrINFN",
        "outputId": "e2e369bb-5ded-466a-9c65-78a90bd9e3bb"
      },
      "source": [
        "%cd automl/efficientnetv2/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/automl/efficientnetv2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5smQA00IOt5"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from effnetv2_model import EffNetV2Model\n",
        "import preprocessing\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMBX4mLVIZHQ",
        "outputId": "99385056-13da-48d3-e0ea-bc4b33eef50e"
      },
      "source": [
        "# Load data\n",
        "\n",
        "image_file = 'panda.jpg'\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O {image_file}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-10 08:57:01--  https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.153.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116068 (113K) [image/jpeg]\n",
            "Saving to: ‘panda.jpg’\n",
            "\n",
            "\rpanda.jpg             0%[                    ]       0  --.-KB/s               \rpanda.jpg           100%[===================>] 113.35K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-09-10 08:57:01 (1.62 MB/s) - ‘panda.jpg’ saved [116068/116068]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NyEMfTbIQNa"
      },
      "source": [
        "MODELS = [\n",
        "    \"efficientnetv2-b0\",\n",
        "    \"efficientnetv2-b1\",\n",
        "    \"efficientnetv2-b2\",\n",
        "    \"efficientnetv2-b3\",\n",
        "    \"efficientnetv2-s\",\n",
        "    \"efficientnetv2-m\",\n",
        "    \"efficientnetv2-l\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D49WvlzIR1a",
        "outputId": "7d1b7dbe-e24b-44f2-8072-410fbc53edd4"
      },
      "source": [
        "# Run for Imagenet-1k pretrained logits:\n",
        "\n",
        "for name in MODELS:\n",
        "    tf.keras.backend.clear_session()\n",
        "  \n",
        "    !curl https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/v2/{name}.tgz | tar xzf -\n",
        "\n",
        "    model = EffNetV2Model(name)\n",
        "\n",
        "    # Initialize variables:\n",
        "    _ = model(tf.ones([1, model.cfg.eval.isize, model.cfg.eval.isize, 3]), training=False)\n",
        "    \n",
        "    # Load weights:\n",
        "    ckpt_path = os.path.join(os.getcwd(), name)\n",
        "    if tf.io.gfile.isdir(ckpt_path):\n",
        "        ckpt_path = tf.train.latest_checkpoint(ckpt_path)\n",
        "    model.load_weights(ckpt_path)\n",
        "\n",
        "    print(f\"Model variant: {name}\")\n",
        "    print(f\"Train image size: {model.cfg.train.isize}\")\n",
        "    print(f\"Eval image size: {model.cfg.eval.isize}\")\n",
        "    print()\n",
        "\n",
        "    image = tf.image.decode_jpeg(tf.io.read_file(image_file))\n",
        "    input_tensor = preprocessing.preprocess_image(\n",
        "        image,\n",
        "        image_size=model.cfg.eval.isize,\n",
        "        is_training=False\n",
        "    )\n",
        "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "\n",
        "    logits = model(input_tensor, training=False)\n",
        "\n",
        "    np.save(\n",
        "        f\"/content/{name}_{model.cfg.eval.isize}_original_logits.npy\", \n",
        "        logits.numpy()\n",
        "    )    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  100M  100  100M    0     0  54.4M      0  0:00:01  0:00:01 --:--:-- 54.4M\n",
            "Model variant: efficientnetv2-b0\n",
            "Train image size: 192\n",
            "Eval image size: 224\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  114M  100  114M    0     0  48.0M      0  0:00:02  0:00:02 --:--:-- 48.0M\n",
            "Model variant: efficientnetv2-b1\n",
            "Train image size: 192\n",
            "Eval image size: 240\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  142M  100  142M    0     0  50.6M      0  0:00:02  0:00:02 --:--:-- 50.5M\n",
            "Model variant: efficientnetv2-b2\n",
            "Train image size: 208\n",
            "Eval image size: 260\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  202M  100  202M    0     0  50.9M      0  0:00:03  0:00:03 --:--:-- 50.9M\n",
            "Model variant: efficientnetv2-b3\n",
            "Train image size: 240\n",
            "Eval image size: 300\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  302M  100  302M    0     0  48.6M      0  0:00:06  0:00:06 --:--:-- 51.3M\n",
            "Model variant: efficientnetv2-s\n",
            "Train image size: 300\n",
            "Eval image size: 384\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  762M  100  762M    0     0  45.2M      0  0:00:16  0:00:16 --:--:-- 41.4M\n",
            "Model variant: efficientnetv2-m\n",
            "Train image size: 384\n",
            "Eval image size: 480\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1659M  100 1659M    0     0  56.1M      0  0:00:29  0:00:29 --:--:-- 58.3M\n",
            "Model variant: efficientnetv2-l\n",
            "Train image size: 384\n",
            "Eval image size: 480\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07wgKevlItYu",
        "outputId": "cd36409c-b78e-4588-8fbc-1be3ef308b83"
      },
      "source": [
        "# Run for Imagenet-1k pretrained features:\n",
        "for name in MODELS:\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Do not redownload weights if present:\n",
        "    ![ -e $name ] || curl https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/v2/{name}.tgz | tar xzf -\n",
        "\n",
        "    model = EffNetV2Model(name, include_top=False)\n",
        "\n",
        "    # Initialize variables:\n",
        "    _ = model(tf.ones([1, model.cfg.eval.isize, model.cfg.eval.isize, 3]), training=False)\n",
        "    \n",
        "    # Load weights:\n",
        "    ckpt_path = os.path.join(os.getcwd(), name)\n",
        "    if tf.io.gfile.isdir(ckpt_path):\n",
        "        ckpt_path = tf.train.latest_checkpoint(ckpt_path)\n",
        "    model.load_weights(ckpt_path)\n",
        "\n",
        "    print(f\"Model variant: {name}\")\n",
        "    print(f\"Train image size: {model.cfg.train.isize}\")\n",
        "    print(f\"Eval image size: {model.cfg.eval.isize}\")\n",
        "    print()\n",
        "\n",
        "    image = tf.image.decode_jpeg(tf.io.read_file(image_file))\n",
        "    input_tensor = preprocessing.preprocess_image(\n",
        "        image,\n",
        "        image_size=model.cfg.eval.isize,\n",
        "        is_training=False\n",
        "    )\n",
        "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "\n",
        "    features = model(input_tensor, training=False)\n",
        "\n",
        "    np.save(\n",
        "        f\"/content/{name}_{model.cfg.eval.isize}_original_features.npy\", \n",
        "        features.numpy()\n",
        "    )    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model variant: efficientnetv2-b0\n",
            "Train image size: 192\n",
            "Eval image size: 224\n",
            "\n",
            "Model variant: efficientnetv2-b1\n",
            "Train image size: 192\n",
            "Eval image size: 240\n",
            "\n",
            "Model variant: efficientnetv2-b2\n",
            "Train image size: 208\n",
            "Eval image size: 260\n",
            "\n",
            "Model variant: efficientnetv2-b3\n",
            "Train image size: 240\n",
            "Eval image size: 300\n",
            "\n",
            "Model variant: efficientnetv2-s\n",
            "Train image size: 300\n",
            "Eval image size: 384\n",
            "\n",
            "Model variant: efficientnetv2-m\n",
            "Train image size: 384\n",
            "Eval image size: 480\n",
            "\n",
            "Model variant: efficientnetv2-l\n",
            "Train image size: 384\n",
            "Eval image size: 480\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO-DPHMPJQL6"
      },
      "source": [
        "# Collect logits for imagenet-21k pretrained variants:\n",
        "MODELS = [\n",
        "    \"efficientnetv2-s\",\n",
        "    \"efficientnetv2-m\",\n",
        "    \"efficientnetv2-l\",\n",
        "    \"efficientnetv2-xl\",\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCDHHSKPJvCO",
        "outputId": "21183aac-1c30-4275-fc1b-546a99bcc6ff"
      },
      "source": [
        "for name in MODELS:\n",
        "    tf.keras.backend.clear_session()\n",
        "    !curl https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/v2/{name}-21k-ft1k.tgz | tar xzvf -\n",
        "\n",
        "    model = EffNetV2Model(name)\n",
        "    _ = model(tf.ones([1, model.cfg.eval.isize, model.cfg.eval.isize, 3]), training=False)\n",
        "    \n",
        "    ckpt_path = os.path.join(os.getcwd(), f\"{name}-21k-ft1k\")\n",
        "    if tf.io.gfile.isdir(ckpt_path):\n",
        "        ckpt_path = tf.train.latest_checkpoint(ckpt_path)\n",
        "    \n",
        "    model.load_weights(ckpt_path)\n",
        "\n",
        "    print(f\"Model variant: {name}\")\n",
        "    print(f\"Train image size: {model.cfg.train.isize}\")\n",
        "    print(f\"Eval image size: {model.cfg.eval.isize}\")\n",
        "    print()\n",
        "\n",
        "    image = tf.image.decode_jpeg(tf.io.read_file(image_file))\n",
        "    input_tensor = preprocessing.preprocess_image(\n",
        "        image,\n",
        "        image_size=model.cfg.eval.isize,\n",
        "        is_training=False\n",
        "    )\n",
        "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "\n",
        "    logits = model(input_tensor, training=False)\n",
        "\n",
        "    np.save(\n",
        "        f\"/content/{name}_{model.cfg.eval.isize}_21k-ft1k_original_logits.npy\", \n",
        "        logits.numpy()\n",
        "    )    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0efficientnetv2-s-21k-ft1k/\n",
            "efficientnetv2-s-21k-ft1k/model.meta\n",
            " 34  303M   34  105M    0     0  49.9M      0  0:00:06  0:00:02  0:00:04 49.9Mefficientnetv2-s-21k-ft1k/model.index\n",
            "efficientnetv2-s-21k-ft1k/checkpoint\n",
            "efficientnetv2-s-21k-ft1k/model.data-00000-of-00001\n",
            "100  303M  100  303M    0     0  54.4M      0  0:00:05  0:00:05 --:--:-- 56.6M\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py:1361: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py:1361: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model variant: efficientnetv2-s\n",
            "Train image size: 300\n",
            "Eval image size: 384\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0efficientnetv2-m-21k-ft1k/\n",
            "  0  76efficientnetv2-m-21k-ft1k/model.meta\n",
            " 43  762M   43  330M    0     0  53.9M      0  0:00:14  0:00:06  0:00:08 54.6Mefficientnetv2-m-21k-ft1k/model.index\n",
            "efficientnetv2-m-21k-ft1k/checkpoint\n",
            "efficientnetv2-m-21k-ft1k/model.data-00000-of-00001\n",
            "100  762M  100  762M    0     0  55.5M      0  0:00:13  0:00:13 --:--:-- 54.4M\n",
            "Model variant: efficientnetv2-m\n",
            "Train image size: 384\n",
            "Eval image size: 480\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0efficientnetv2-l-21k-ft1k/\n",
            "efficientnetv2-l-21k-ft1k/model.meta\n",
            " 48 1632M   48  789M    0     0  48.5M      0  0:00:33  0:00:16  0:00:17 50.0Mefficientnetv2-l-21k-ft1k/model.index\n",
            "efficientnetv2-l-21k-ft1k/checkpoint\n",
            "efficientnetv2-l-21k-ft1k/model.data-00000-of-00001\n",
            "100 1632M  100 1632M    0     0  50.5M      0  0:00:32  0:00:32 --:--:-- 44.9M\n",
            "Model variant: efficientnetv2-l\n",
            "Train image size: 384\n",
            "Eval image size: 480\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0efficientnetv2-xl-21k-ft1k/\n",
            "efficientnetv2-xl-21k-ft1k/model.meta\n",
            " 48 2895M   48 1411M    0     0  49.6M      0  0:00:58  0:00:28  0:00:30 41.6Mefficientnetv2-xl-21k-ft1k/model.index\n",
            "efficientnetv2-xl-21k-ft1k/checkpoint\n",
            "efficientnetv2-xl-21k-ft1k/model.data-00000-of-00001\n",
            "100 2895M  100 2895M    0     0  49.7M      0  0:00:58  0:00:58 --:--:-- 49.3M\n",
            "Model variant: efficientnetv2-xl\n",
            "Train image size: 384\n",
            "Eval image size: 512\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HStwxESo7_pP"
      },
      "source": [
        "# Get extracted feature shape for more sanity checks regarding shape:"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmSLpWvL8FbK"
      },
      "source": [
        "# Add     print(outputs.shape)\n",
        "# to line 474 in effnetv2_models.py"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MtgRVR8YTW"
      },
      "source": [
        "# RESTART RUNTIME"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7zryHw_8fOm",
        "outputId": "ec8b55ee-9e05-4db7-c501-ef7351d612b0"
      },
      "source": [
        "%cd automl/efficientnetv2/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/automl/efficientnetv2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hjaq7pR8gTQ"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from effnetv2_model import EffNetV2Model\n",
        "import preprocessing\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E1Q1_nh8mEO"
      },
      "source": [
        "MODELS = [\n",
        "    \"efficientnetv2-b0\",\n",
        "    \"efficientnetv2-b1\",\n",
        "    \"efficientnetv2-b2\",\n",
        "    \"efficientnetv2-b3\",\n",
        "    \"efficientnetv2-s\",\n",
        "    \"efficientnetv2-m\",\n",
        "    \"efficientnetv2-l\",\n",
        "    \"efficientnetv2-xl\",\n",
        "]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etPQdUlH8IKi",
        "outputId": "8955d686-1596-4031-fdbe-e02d23f586fc"
      },
      "source": [
        "for name in MODELS:\n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "\n",
        "    print(f\"Model variant: {name}\")\n",
        "    model = EffNetV2Model(name, include_top=False)\n",
        "    _ = model(tf.ones([1, model.cfg.eval.isize, model.cfg.eval.isize, 3]), training=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model variant: efficientnetv2-b0\n",
            "(1, 7, 7, 1280)\n",
            "Model variant: efficientnetv2-b1\n",
            "(1, 8, 8, 1280)\n",
            "Model variant: efficientnetv2-b2\n",
            "(1, 9, 9, 1408)\n",
            "Model variant: efficientnetv2-b3\n",
            "(1, 10, 10, 1536)\n",
            "Model variant: efficientnetv2-s\n",
            "(1, 12, 12, 1280)\n",
            "Model variant: efficientnetv2-m\n",
            "(1, 15, 15, 1280)\n",
            "Model variant: efficientnetv2-l\n",
            "(1, 15, 15, 1280)\n",
            "Model variant: efficientnetv2-xl\n",
            "(1, 16, 16, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B71mPZ9NKaVk",
        "outputId": "543d58d3-d41a-4d89-da46-8c4d361b234d"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJL2xU1qKxCC",
        "outputId": "f3ff9c30-03bb-4838-9f55-d2cf490291d3"
      },
      "source": [
        "!tar czvf efficientnet-v2-outputs.tar.gz *.npy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "efficientnetv2-b0_224_original_features.npy\n",
            "efficientnetv2-b0_224_original_logits.npy\n",
            "efficientnetv2-b1_240_original_features.npy\n",
            "efficientnetv2-b1_240_original_logits.npy\n",
            "efficientnetv2-b2_260_original_features.npy\n",
            "efficientnetv2-b2_260_original_logits.npy\n",
            "efficientnetv2-b3_300_original_features.npy\n",
            "efficientnetv2-b3_300_original_logits.npy\n",
            "efficientnetv2-l_480_21k-ft1k_original_features.npy\n",
            "efficientnetv2-l_480_21k-ft1k_original_logits.npy\n",
            "efficientnetv2-l_480_original_features.npy\n",
            "efficientnetv2-l_480_original_logits.npy\n",
            "efficientnetv2-m_480_21k-ft1k_original_features.npy\n",
            "efficientnetv2-m_480_21k-ft1k_original_logits.npy\n",
            "efficientnetv2-m_480_original_features.npy\n",
            "efficientnetv2-m_480_original_logits.npy\n",
            "efficientnetv2-s_384_21k-ft1k_original_features.npy\n",
            "efficientnetv2-s_384_21k-ft1k_original_logits.npy\n",
            "efficientnetv2-s_384_original_features.npy\n",
            "efficientnetv2-s_384_original_logits.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te_ufFu1K3Co"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qYdIT5vDK6Yp",
        "outputId": "2dd5dfb3-07bc-4063-cfed-ffe9010dc805"
      },
      "source": [
        "files.download(\"efficientnet-v2-outputs.tar.gz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2b72a664-c1e3-4a9e-ac98-005f1df17d36\", \"efficientnet-v2-outputs.tar.gz\", 87216)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x16phivK90u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
